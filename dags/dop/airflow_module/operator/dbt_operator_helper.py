import logging
import os

from airflow.contrib.hooks.gcs_hook import GoogleCloudStorageHook

# List of files generated by dbt docs generate
# https://docs.getdbt.com/reference/commands/cmd-docs
DBT_DOC_FILES = ["index.html", "manifest.json", "catalog.json"]
DBT_DOC_FOLDER = "target"

def implode_arguments(dbt_arguments, filter_func=None):
    filtered_dbt_arguments = (
        filter_func(dbt_arguments) if filter_func else dbt_arguments
    )
    return " ".join(
        [
            " ".join(
                [
                    argument["option"],
                    "" if argument.get("value") is None else argument.get("value"),
                ]
            )
            for argument in filtered_dbt_arguments
        ]
    )


def parsed_cmd_airflow_context_vars(context):
    cmd = '"{'
    context_vars = ["ds", "ds_nodash", "ts", "ts_nodash", "ts_nodash_with_tz"]
    if context:
        var_list = [f"'{v}'" + f": '{context[v]}'" for v in context_vars]
    else:
        var_list = [f"'{v}'" + ": '{{ " + v + " }}'" for v in context_vars]
    cmd += ",".join(var_list)

    cmd += '}"'

    return cmd


def extract_argument(dbt_arguments: list, name: str, default_value: str = None):
    """
    Extract an argument from the argument list. Format is
    [
        {'option': 'OPTION1', 'value': 'VALUE1'},
        {'option': 'OPTION2', 'value': 'VALUE2'},
        ...
    ]

    :param dbt_arguments: Argument list
    :param name: Argument to extract
    :param default_value: Default value to return if not present
    """
    return next(
        (arg.get("value") for arg in dbt_arguments if arg.get("option") == name),
        default_value,
    )


def copy_docs_to_gcs(bucket: str, bucket_path: str, project_path: str):
    """
    Copy doc files generated with dbt docs generate to GCS

    :param bucket: Bucket where the doc files will be copied
    :param bucket_path: Path in the bucket
    :param project_path: Local project folder
    """
    hook = GoogleCloudStorageHook()
    for doc_file in DBT_DOC_FILES:
        doc_file_path = f"{project_path}/{DBT_DOC_FOLDER}/{doc_file}"
        if os.path.exists(doc_file_path):
            logging.info(f"{doc_file} found. Copying to gs://{bucket}/{bucket_path}")
            hook.upload(
                bucket,
                object=f"{bucket_path}/{doc_file}" if bucket_path else doc_file,
                filename=doc_file_path,
                mime_type= "text/html" if doc_file.endswith(".html") else "application/json",
            )
        else:
            logging.warning(f"{doc_file} not found. Skipping")
